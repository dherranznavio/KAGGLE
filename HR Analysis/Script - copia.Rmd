---
title: "Human Resources Analysis"
author: "Daniel Herranz"
date: "6 de marzo de 2017"
output: html_document
---

In this exercise is trying to understand why the employees of a company are leaving and predict will be next. 


The report are split in the following steps:

  1- Read and clean the data.

  2- Exploratory data analysis.

  3- Machine learning.

 
```{r echo=FALSE, message=FALSE, include=FALSE}
library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
```

# 1- READ THE DATA.

```{r read data}
hr_data <- read.table("../input/HR_comma_sep.csv", sep = ",", header = T)
```
### Take a look to data set
```{r echo = FALSE}
str(hr_data)
```

### Review the format of variables.  
```{r}
#Format the data
hr_data$Work_accident <-factor(hr_data$Work_accident,labels=c("NO_ACCIDENT","YES_ACCIDENT"))
hr_data$left <-   factor(hr_data$left, labels =c("NO_LEFT","YES_LEFT"))
hr_data$promotion_last_5years <- factor(hr_data$promotion_last_5year,labels =c("NO_PROMOTION","YES_PROMOTION"))

#Names of columns
colnames(hr_data)[colnames(hr_data)=="sales"] <- "department"
```

### Review NULL values. 
```{r}
sapply(hr_data, function(x) sum(is.na(x)))
```
#####  There is no NULL value



# 2- Exploratory data analysis.

## Preview header
```{r}
head(hr_data)
```
## Review type of data, dispersion analysis, count of cathegorical 
```{r }
summary(hr_data)  
```

## The data set is formed by the following values:
 * Employee satisfaction level (satisfaction_level)
 * Last evaluation (last_evaluation)
 * Number of projects (number_project)
 * Average monthly hours (average_montly_hours)
 * Time spent at the company (time_spend_company)
 * Whether they have had a work accident (Work_accident)
 * Whether they have had a promotion in the last 5 years (promotion_last_5years)
 * Sales (sales)
 * Salary (salary)
 * Whether the employee has left (left)


## 2.1 - First look of the data

```{r}
hr_data_long <-  melt(hr_data, values = colnames(hr_data_long))

ggplot(hr_data_long,aes(x = value , fill = left)) +  geom_bar()  + facet_wrap(~variable, scales = 'free') + ylab("Frecuency") 
```

```{r}
par(mfrow=c(1,3))
par(col.lab="red")
plot(table(hr_data$left, hr_data$promotion_last_5year), main="LEFT VS SENIORITY")
plot(table(hr_data$left, hr_data$salary), main="LEFT VS SALARY")
plot(table(hr_data$left, hr_data$promotion_last_5years), main="LEFT VS PROMOTION")
```

## 2.2 -How many employees left the company?

### Total of employees left the company 
```{r}
left_total <- count(hr_data,left) 
left_total <-  transform(left_total,percentage = left_total$n/sum(left_total$n)*100)

ggplot(data=left_total, aes(x=left, y=percentage, fill =left)) +
  geom_bar(stat="identity") + guides(fill=FALSE)
```

 23,85% employees leaves the company.

### Total of employees left the company by department
```{r}

query <- hr_data %>% select(department,left) %>%
  filter(left == "YES_LEFT") %>%
  group_by(department) %>%
  summarise(total=n()) %>%
  mutate(ratio = (total/sum(total)*100)) 

query

ggplot(data=query, aes(x=department, y=ratio, fill = ratio)) +
  geom_bar(stat="identity") + guides(fill=FALSE) + ylab("percentage")

```

It is in sale, support and technical departments whith highest leave ratio 



## 2.4 -Why leave the company?

```{r library, echo=FALSE, message=FALSE, include=FALSE}
library(party)
```


```{r}
hr_data$left <-   factor(hr_data$left, labels =c("NO","YES"))
```

```{r, out.width = '1800px', out.height = '1200px'}
model.ctree <- ctree(left ~ ., data = hr_data, controls = ctree_control(mincriterion = 0.7, maxdepth = 4))
plot(model.ctree, 
       inner_panel=node_inner(model.ctree,
                              id= FALSE,
                              abbreviate = FALSE,           # short variable names
                              pval = FALSE),                # no p-values     
      terminal_panel=node_barplot(model.ctree, id= FALSE))
```

Satisfaccion level and time spend company are the more relevant values to determine if an employee leave or not the company. 

Who employees left the company?

- Employees with lower satisfaccion level and not much number of proyects.
- Employees with lower satisfaccion level with number of projects greater than 6 years or less than 6 years but work a lot of hours   
- Employees with higher satisfaccion level and good evaluation, with seniority between 4-6 years. 




#3- Machine learning.

## 3.1 - Split the data into training and testing . 
```{r include = FALSE}
library(caret)
```

```{r}
Index <- createDataPartition(hr_data$left, p = .70,list = FALSE, times = 1)
train_hr <- hr_data[ Index,]
test_hr <- hr_data[-Index,]

print(table(train_hr$left))
print(table(test_hr$left))

```

#3.2 - Using random forest to predict
```{r include = FALSE}
library(randomForest)
```

```{r}
arbol.area <- randomForest(left ~ ., data = train_hr)
```
```{r}
plot(arbol.area)
```
Dotchart of variable importance 
```{r}
varImpPlot(arbol.area) 
```

#3.3 - Analyse the result of performing algorithm 

## Confustion matrix

Also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one (in unsupervised learning it is usually called a matching matrix). Each column of the matrix represents the instances in a predicted class while each row represents the instances in an actual class (or vice versa). The name stems from the fact that it makes it easy to see if the system is confusing two classes (i.e. commonly mislabelling one as another).

https://en.wikipedia.org/wiki/Confusion_matrix

```{r}
predict <- predict(arbol.area,test_hr)
confusionMatrix(predict,test_hr$left)
```

The meaning of the principal  ratios are:

####Sensitivity
The chance of testing positive among those with the condition
The chance of rejecting the null hypothesis among those that do not satisfy the null hypothesis
1 - Type II Error
TP / (TP + FN) = n11 / (n10 + n11)

####Specificity or Selectivity
The chance of testing negative among those without the condition
The chance of accepting the null hypothesis among those that satisfy the null hypothesis
1 - Type I Error
TN / (TN + FP) = n00 / (n00 + n01)

####Positive Predictive Value
The chance of having the condition among those that test positive
The chance of not satisfying the null hypothesis among those that reject the null hypothesis
1 - False Discovery Rate
TP / (TP + FP) = n11 / (n01 + n11)

####Negative Predictive Value
The chance of not having the condition among those that test negative
The chance of satisfying the null hypothesis among those that accept the null hypothesis
1 - False Omission Rate
TN / (TN + FN) = n00 / (n00 + n10)


#ROC curve

```{r include = FALSE}
library(pROC)
```
In statistics, a receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the performance of a binary classifier system as its discrimination threshold is varied. The curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. The true-positive rate is also known as sensitivity, recall or probability of detection[1] in machine learning. The false-positive rate is also known as the fall-out or probability of false alarm[1] and can be calculated as (1 âˆ’ specificity). The ROC curve is thus the sensitivity as a function of fall-out. In general, if the probability distributions for both detection and false alarm are known, the ROC curve can be generated by plotting the cumulative distribution function (area under the probability distribution from {\displaystyle -\infty } -\infty  to the discrimination threshold) of the detection probability in the y-axis versus the cumulative distribution function of the false-alarm probability in x-axis.

ROC analysis provides tools to select possibly optimal models and to discard suboptimal ones independently from (and prior to specifying) the cost context or the class distribution. ROC analysis is related in a direct and natural way to cost/benefit analysis of diagnostic decision making.

https://en.wikipedia.org/wiki/Receiver_operating_characteristic


```{r}
plot(roc(as.numeric(test_hr$left), as.numeric(predict)),  print.thres=TRUE)
```




