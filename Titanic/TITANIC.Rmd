---
title: "TITANIC"
author: "Daniel Herranz"
date: "13 de marzo de 2017"
output: html_document
---

This is my first exercise created in datacamp.
Some parts of the exercise has been adapted to fix the differences between datacamp and kaggle data. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# READ THE DATA.
 Import the training set: train
```{r}
train <-read.table("../input/train.csv", sep = ",", header = T)
```
 Import the testing set: test
```{r}
test <-read.table("../input/test.csv", sep = ",", header = T)
```


# EXPLORATORY DATA ANALYSIS.

 Your train and test set are still loaded
```{r}
str(train)
str(test)
```
 Survival rates in absolute numbers
```{r}
table(train$Survived)
```
 Survival rates in proportions
```{r}
prop.table(table(train$Survived))
```
 Two-way comparison: Sex and Survived
```{r}
table( train$Sex, train$Survived)
```
 Two-way comparison: row-wise proportions
```{r}
prop.table(table(train$Sex, train$Survived), 1)
```
 Create the column child, and indicate whether child or no child
```{r}
train$Child <- NA
train$Child[train$Age < 18] <- 1
train$Child[train$Age >= 18] <- 0
```
 Two-way comparison
```{r}
prop.table(table(train$Child, train$Survived),1)
```

```{r echo = FALSE}
#Copy of test
test_one <- test

# Initialize a Survived column to 0
test_one$Survived <- 0

# Set Survived to 1 if Sex equals "female"
test_one$Survived[test_one$Sex == "female"] <- 1
```


# 2- Create a decision tree.
  
 Load in the R package  
```{r include= FALSE}
library(rpart)
```
 Build the decision tree
```{r}
my_tree_two <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data = train, method = "class")
```
 Load in the packages to build a fancy plot
```{r include = FALSE}
library(rattle)
library(rpart.plot)
library(RColorBrewer)
```
 Time to plot your fancy tree
```{r}
fancyRpartPlot(my_tree_two)
```

# PREDICT

 my_tree_two and test are available in the workspace
 Make predictions on the test set

```{r} 
my_prediction <- predict(my_tree_two, test, type = "class")

# Finish the data.frame() call
my_solution <- data.frame(PassengerId = test$PassengerId, Survived = my_prediction)

# Use nrow() on my_solution
nrow(my_solution)

# Finish the write.csv() call
write.csv(my_solution, file = "my_solution.csv", row.names = FALSE)

```

# OVERFITTING
Your train and test set are still loaded in

```{r}
my_tree_three <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, 
                       data = train, method = "class", control = rpart.control(minsplit = 50, cp = 0))

fancyRpartPlot(my_tree_three)

# train and test are available

# Create train_two
train_two <- train
train_two$family_size <- train_two$SibSp + train_two$Parch + 1

# Finish the command
my_tree_four <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + family_size, 
                      data = train_two, method = "class")

# Visualize your new decision tree
fancyRpartPlot(my_tree_four)
```


#PASSENGER SURVIVAL

# train_new and test_new are available in the workspace
```{r}
# Finish the command
my_tree_five <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, 
                      data =train, method = "class")

# Visualize my_tree_five
fancyRpartPlot(my_tree_five)

# Make prediction
my_prediction <- predict(my_tree_five, test, type = "class")

# Make results ready for submission
my_solution <- data.frame(PassengerId = test$PassengerId, Survived = my_prediction)
write.csv(my_solution, file = "my_solution.csv", row.names = FALSE)

```


#RANDOM FOREST 
```{r}
all_data <- read.table("../input/train.csv", sep = ",", header = T)

# Passenger on row 62 and 830 do not have a value for embarkment. 
# Since many passengers embarked at Southampton, we give them the value S.
all_data$Embarked[c(62, 830)] <- "S"

# Factorize embarkment codes.
all_data$Embarked <- factor(all_data$Embarked)

# # Passenger on row 1044 has an NA Fare value. Let's replace it with the median fare value.
# all_data$Fare[1044] <- median(all_data$Fare, na.rm = TRUE)

# How to fill in missing Age values?
# We make a prediction of a passengers Age using the other variables and a decision tree model. 
# This time you give method = "anova" since you are predicting a continuous variable.
library(rpart)
predicted_age <- rpart(Age ~ . ,
                       data = all_data[!is.na(all_data$Age),], method = "anova")
all_data$Age[is.na(all_data$Age)] <- predict(predicted_age, all_data[is.na(all_data$Age),])

# Split the data back into a train set and a test set
train <- all_data[1:891,]
test <- all_data[892:1309,]


# train and test are available in the workspace
str(train)
str(test)

# Load in the package
library(randomForest)

# Set seed for reproducibility
set.seed(111)

# Apply the Random Forest Algorithm
my_forest <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, 
                          data = train, importance = TRUE, ntree = 1000)

# Make your prediction using the test set
my_prediction <- predict(my_forest, test)

# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions
my_solution <- data.frame(PassengerId = test$PassengerId, Survived = my_prediction)
```
